# DINSTestTask

## Требования
 + Java 8
 + Docker
 + Docker-compose
 + Maven
 
 ## Запуск
 Необходимые порты для запуска на localhost: `3306` `9092` `2181`. Для запуска тестов необходим еще `4445`
 
 Также джаве необходимы права для сниффинга
 
 `sudo setcap cap_net_raw,cap_net_admin=eip /path/to/java`
 
 Клонируем репозиторий
 ```
 mkdir ~/Task
 cd ~/Task
 git clone https://github.com/Fagam32/DINSTestTask
 cd ~/Task/DINSTestTask
 ```
 Создаем jar
 
 `mvn clean package`
 
 
 Собираем и запускаем контейнеры
 
 ```
 docker-compose build
 docker-compose up
 ```
 
 Запускаем проект:
 
 `java -jar target/name_of_jar [options]`
 
 
 Опции:
 + `from=ip:host` ИЛИ `from=ip`
 + `to=ip:host` ИЛИ `to=ip:host`
 + Можно использовать обе сразу
 + Если опций нет, то считается весь трафик
 
 ## Итоги
 
 ### 1.
`Создать в БД схему traffic_limits с таблицей limits_per_hour. Таблица должна содержать 3
колонки: limit_name, limit_value, effective_date. Задать 2 лимита: min=1024, max=1073741824.
В колонку effective_date внести дату, начиная с которой эти лимиты вступают в силу.`
 
 + Схема, таблица и первые значения в MySQL создаются самим приложением
 
 ### 2.
 `Написать приложение на Spark Streaming, которое, используя любую общедоступную
библиотеку для обработки трафика (Pcap4J, jpcap, etc), будет считать объем захваченного
трафика за 5 минут и в случае выхода за пределы минимального и максимального значения
будет посылать сообщение в Kafka в топик alerts. Сообщение должно посылаться всякий раз,
когда объем трафика за 5 минут пересекает любое из пороговых значений.`
 
 + Трафик считывается и, если он < min или > max, то сообщение отправляется в Kafka в топик alert
 + Размер "большого" окна - 5 минут. Оно "двигается" каждые 15 секунд. То есть сообщения теоретически могут отправляется каждые 15 секунд (может быть 2 за раз если min > max)
 + Используется Pcap4J
 
### 3.
`Приложение должно обновлять пороговые значения каждые 20 минут (следует брать значения с максимальной effective_date).`

+ Об этом ниже

### 4.
`Написать unit тесты.`

+ Написаны совсем базовые. В силу огромного количества новых инструментов(И Kafka, и Spark, и Docker)

### 5.
`Предусмотреть возможность считать только тот трафик, который отправляется/принимается
на/с определенного IP-адреса, который задается в качестве аргумента при сабмите. По
умолчанию (если IP не указан) должен учитываться весь трафик.`

+ Опции при запуске jar файла это и есть

### 6.
`Предусмотреть возможность обновления пороговых значений сразу после их обновления в
базе данных.`

+ Этот и пункт 4 взаимоисключающие(если я правильно все понял). Лимиты пытаются обновиться каждую секунду. То есть если в БД добавляется запись, то не более чем через секунду они обновятся(зависит от кол-ва реальных потоков на машине).

### Общее
 + Все тесты и разработка делались в Linux Mint 19.3
 + В целом, считаются все пакеты, включая "рукопожатия" по TCP
 + Логи идут в папку /projectPath/logs/
 + Нет гарантии на то, что сообщение дойдет. Fire and forget
 + Очень много Singletonов

 
